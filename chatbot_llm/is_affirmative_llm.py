"""
affirmative_llm.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- ì‚¬ìš©ì ì…ë ¥(utterance)ì„ ê¸°ë°˜ìœ¼ë¡œ
  LLMì—ê²Œ ê¸ì • ì—¬ë¶€ë¥¼ íŒë³„í•˜ë„ë¡ ìš”ì²­í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜
"""

import os
from pathlib import Path
from dotenv import load_dotenv
from openai import AsyncOpenAI

# =====================================================
# í™˜ê²½ ì„¤ì • & OpenAI í´ë¼ì´ì–¸íŠ¸
# =====================================================
load_dotenv()
openai = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

PROJECT_ROOT = Path(__file__).resolve().parent.parent
PROMPT_DIR = PROJECT_ROOT / "prompts"

# =====================================================
# ìœ í‹¸ í•¨ìˆ˜
# =====================================================
def load_text_file(path: Path) -> str:
    with open(path, "r", encoding="utf-8") as f:
        return f.read().strip()


# =====================================================
# LLM í˜¸ì¶œ
# =====================================================
async def _call_affirmative_llm(utterance: str) -> bool:
    """
    OpenAIë¥¼ í˜¸ì¶œí•´ ì‚¬ìš©ì ì…ë ¥ì´ ê¸ì •ì¸ì§€ ì•„ë‹Œì§€ë¥¼ íŒë³„í•©ë‹ˆë‹¤.
    """
    # ğŸ”· í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    system_prompt = load_text_file(PROMPT_DIR / "is_affirmative_system_prompt.txt")
    user_prompt_template = load_text_file(PROMPT_DIR / "is_affirmative_user_prompt.txt")
    user_prompt = user_prompt_template.format(utterance=utterance.strip())

    # ğŸ”· LLM í˜¸ì¶œ
    try:
        response = await openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.0
        )
    except Exception as e:
        print(f"âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return False

    content = response.choices[0].message.content.strip()

    # ğŸ”· í›„ì²˜ë¦¬
    if content.startswith("```"):
        content = content.strip("`").strip()
        if content.lower().startswith("json") or content.lower().startswith("python"):
            content = content.split("\n", 1)[-1].strip()

    # ê¸ì • íŒë‹¨
    return content.upper().startswith("YES")


# =====================================================
# is_affirmative í•¨ìˆ˜ (ì™¸ë¶€ í˜¸ì¶œ ì§„ì…ì )
# =====================================================
async def is_affirmative(utterance: str) -> bool:
    """
    ì™¸ë¶€ì—ì„œ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜: ë™ê¸° â†’ ë¹„ë™ê¸° ì‹¤í–‰
    """
    return await _call_affirmative_llm(utterance)


# =====================================================
# CLI í…ŒìŠ¤íŠ¸
# =====================================================
if __name__ == "__main__":
    import asyncio

    example_utterance = "ë„¤ ì§„í–‰í• ê²Œìš”."

    print(f"ì…ë ¥: {example_utterance}")
    result = asyncio.run(is_affirmative(example_utterance))
    print("\nì¶œë ¥:", result)
